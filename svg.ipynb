{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Video Generation \n",
    "### Using a variational recurrent structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy.random import shuffle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim_metric\n",
    "\n",
    "from files.model_svg import *\n",
    "from files.utils import *\n",
    "\n",
    "# Plot configurations\n",
    "%matplotlib inline\n",
    "\n",
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5b99e1351628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_smmnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/VRNN/files/utils.py\u001b[0m in \u001b[0;36mload_smmnist\u001b[0;34m(batch_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_smmnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/mmnist.pickle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Train-test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/envTF24/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;31m# We want to silence any warnings about, e.g. moved modules.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexcs_to_catch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataset, test_dataset = load_smmnist(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our data: visualize one video from the training data\n",
    "visualize_one_video(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_dim, lstm_q_dim, lstm_prior_dim, latent_dim, lstm_dec_dim, lstm_dec_out_dim\n",
    "model = SVG(128, 256, 256, 10, 256, 128, use_skip=True, num_frame=dim_l)\n",
    "model.train(train_dataset, test_dataset, epochs=1000, lr=5e-4, batch_size=batch_size, test_generate_batch_size=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load traind models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('trained_models/model3/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate once on all test videos\n",
    "\n",
    "num_test_videos = 2000\n",
    "\n",
    "ssim = np.zeros((num_test_videos, 15))\n",
    "\n",
    "for x_batch in test_dataset.take(1):\n",
    "    x_batch = x_batch[:num_test_videos,:,:,:,:]\n",
    "    # Initialize with the first frame and condition on the rest like in training\n",
    "    model.svg_cell.x_tm1 = x_batch[:,0,:,:,:]\n",
    "    x_batch = x_batch[:,1:,:,:,:]\n",
    "\n",
    "    # Split x_batch into conditioned ones, and ones that model doesn't know\n",
    "    x_batch_cond, x_batch_gen = tf.split(\n",
    "        x_batch, \n",
    "        num_or_size_splits=[5-1, \n",
    "                            15], \n",
    "        axis=1)\n",
    "    x_batch_gen_numpy = x_batch_gen.numpy()\n",
    "\n",
    "    # Run on the conditioned frames:\n",
    "    out = model(x_batch_cond)\n",
    "    mean, logvar, mean_0, logvar_0, z, x_recons, \\\n",
    "    lstm_q_states, lstm_prior_states, \\\n",
    "    lstm_dec_1_states, lstm_dec_2_states = out\n",
    "    states = [lstm_q_states, lstm_prior_states, lstm_dec_1_states, lstm_dec_2_states]\n",
    "    x_out = x_recons[:,5-2,:,:,:]\n",
    "\n",
    "    # Generate:\n",
    "    print('\\n------- Generating -------+\\n')\n",
    "    print('Original video (15 frames)')\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    for t in range(15):\n",
    "        plt.subplot(1, 15, t+1)\n",
    "        plt.imshow(x_batch_gen[1300,t,:,:,:], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    print('Generated video (15 frames)')\n",
    "    fig = plt.figure(figsize=(16, 4))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "    for t in range(15):\n",
    "        x_out, states = model.svg_cell.generate(x_out, states)\n",
    "        x_out_numpy = x_out.numpy()\n",
    "\n",
    "        plt.subplot(1, 15, t+1)\n",
    "        plt.imshow(x_out[1300,:,:,:], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        for i in range(num_test_videos):\n",
    "            ssim[i, t] = ssim_metric(x_batch_gen_numpy[i,t,:,:,0],\n",
    "                                     x_out_numpy[i,:,:,0])\n",
    "    plt.show()\n",
    "    model.svg_cell.batch_starts = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(np.mean(ssim, axis=1))\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We record SSIM on all test videos 100 times\n",
    "\n",
    "num_test_videos = 2000\n",
    "\n",
    "ssim = np.zeros((100, num_test_videos, 15))\n",
    "\n",
    "x_out_record = np.zeros((100, 1, 15, 64, 64, 1))\n",
    "\n",
    "for samp in range(100):\n",
    "    for x_batch in test_dataset.take(1):\n",
    "        x_batch = x_batch[:num_test_videos,:,:,:,:]\n",
    "        # Initialize with the first frame and condition on the rest like in training\n",
    "        model.svg_cell.x_tm1 = x_batch[:,0,:,:,:]\n",
    "        x_batch = x_batch[:,1:,:,:,:]\n",
    "\n",
    "        # Split x_batch into conditioned ones, and ones that model doesn't know\n",
    "        x_batch_cond, x_batch_gen = tf.split(\n",
    "            x_batch, \n",
    "            num_or_size_splits=[5-1, \n",
    "                                15], \n",
    "            axis=1)\n",
    "        x_batch_gen_numpy = x_batch_gen.numpy()\n",
    "\n",
    "        # Run on the conditioned frames:\n",
    "        out = model(x_batch_cond)\n",
    "        mean, logvar, mean_0, logvar_0, z, x_recons, \\\n",
    "        lstm_q_states, lstm_prior_states, \\\n",
    "        lstm_dec_1_states, lstm_dec_2_states = out\n",
    "        states = [lstm_q_states, lstm_prior_states, lstm_dec_1_states, lstm_dec_2_states]\n",
    "        x_out = x_recons[:,5-2,:,:,:]\n",
    "        x_out_record_tmp = np.zeros((num_test_videos, 15, 64, 64, 1))\n",
    "        for t in range(15):\n",
    "            x_out, states = model.svg_cell.generate(x_out, states)\n",
    "            x_out_numpy = x_out.numpy()\n",
    "            x_out_record_tmp[:,t,:,:,:] = x_out_numpy\n",
    "\n",
    "            for i in range(num_test_videos):\n",
    "                ssim[samp, i, t] = ssim_metric(x_batch_gen_numpy[i,t,:,:,0],\n",
    "                                         x_out_numpy[i,:,:,0])\n",
    "        model.svg_cell.batch_starts = False            \n",
    "    idx = np.argmax(np.mean(ssim[samp,:,:], axis=1))\n",
    "    x_out_record[samp,:,:,:,:,:] = x_out_record_tmp[idx,:,:,:,:]  \n",
    "    print(samp)\n",
    "    \n",
    "with open('results/x_out.pickle', 'wb') as handle:\n",
    "    pickle.dump(x_out_record, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('results/ssim_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(ssim, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot 100 times on a chosen video\n",
    "\n",
    "video_idx = 257\n",
    "ssim = np.zeros((100, 15))\n",
    "model.svg_cell.batch_starts = False\n",
    "\n",
    "for samp in range(100):\n",
    "\n",
    "    for x_batch in test_dataset.take(1):\n",
    "        x_batch = tf.expand_dims(x_batch[video_idx,:,:,:,:], axis=0)\n",
    "\n",
    "        model.svg_cell.x_tm1 = x_batch[:,0,:,:,:]\n",
    "        x_batch = x_batch[:,1:,:,:,:]\n",
    "\n",
    "        # Split x_batch into conditioned ones, and ones that model doesn't know\n",
    "        x_batch_cond, x_batch_gen = tf.split(\n",
    "            x_batch, \n",
    "            num_or_size_splits=[5-1, \n",
    "                                15], \n",
    "            axis=1)\n",
    "        x_batch_gen_numpy = x_batch_gen.numpy()\n",
    "\n",
    "        # Run on the conditioned frames:\n",
    "        out = model(x_batch_cond)\n",
    "        mean, logvar, mean_0, logvar_0, z, x_recons, \\\n",
    "        lstm_q_states, lstm_prior_states, \\\n",
    "        lstm_dec_1_states, lstm_dec_2_states = out\n",
    "        states = [lstm_q_states, lstm_prior_states, lstm_dec_1_states, lstm_dec_2_states]\n",
    "        x_out = x_recons[:,5-2,:,:,:]\n",
    "\n",
    "        # Generate:\n",
    "        print('\\n------- Generating -------+', samp)\n",
    "        print('Original video (15 frames)')\n",
    "        fig = plt.figure(figsize=(16, 4))\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "        for t in range(15):\n",
    "            plt.subplot(1, 15, t+1)\n",
    "            plt.imshow(x_batch_gen[0,t,:,:,:], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        print('Generated video (15 frames)')\n",
    "        fig = plt.figure(figsize=(16, 4))\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "        for t in range(15):\n",
    "            x_out, states = model.svg_cell.generate(x_out, states)\n",
    "            x_out_numpy = x_out.numpy()\n",
    "            ssim[samp, t] = ssim_metric(x_batch_gen_numpy[0,t,:,:,0],\n",
    "                                        x_out_numpy[0,:,:,0])\n",
    "\n",
    "            plt.subplot(1, 15, t+1)\n",
    "            plt.imshow(x_out[0,:,:,:], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    "        model.svg_cell.batch_starts = False  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.mean(ssim, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1000)),model.loss_list)\n",
    "plt.title('Loss value across epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.savefig('figs/loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = pd.read_pickle('ssim_test_model3.pickle')\n",
    "\n",
    "plt.plot(list(range(5, 20)),np.mean(ssim, axis=(0,1)))\n",
    "plt.title('Mean SSIM across time-steps')\n",
    "plt.xlabel('Time-steps')\n",
    "plt.ylabel('Mean SSIM')\n",
    "plt.savefig('figs/ssim.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the test videos\n",
    "\n",
    "for x_batch in test_dataset.take(1):\n",
    "    for frame in range(2000):\n",
    "        # Plot:\n",
    "        print('Original video (15 frames)', frame)\n",
    "        fig = plt.figure(figsize=(16, 2))\n",
    "        plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "        for t in range(15):\n",
    "            plt.subplot(1, 15, t+1)\n",
    "            plt.imshow(x_batch[frame, t+5,:,:,:], cmap='gray')\n",
    "            plt.axis('off')\n",
    "        plt.show()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "tree is already the newest version (1.7.0-5).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnuma1\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install tree\n",
    "!tree ./ >> README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
